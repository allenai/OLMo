# Defines a CUDA-enabled Docker image suitable for running this project's experiments
# via beaker-gantry.

FROM ubuntu:24.04

ENV LC_ALL=C.UTF-8
ENV LANG=C.UTF-8
ENV NVIDIA_VISIBLE_DEVICES all
ENV NVIDIA_DRIVER_CAPABILITIES compute,utility
ENV LD_LIBRARY_PATH /usr/local/nvidia/lib:/usr/local/nvidia/lib64
ARG DEBIAN_FRONTEND="noninteractive"

# Install conda
RUN  apt-get update && \
     apt-get install -y --no-install-recommends \
        build-essential \
        ca-certificates \
        curl \
        wget \
        libxml2-dev \
        jq \
        git && \
    rm -rf /var/lib/apt/lists/* && \
    curl -fsSL -v -o ~/miniconda.sh -O  https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh && \
    chmod +x ~/miniconda.sh && \
    ~/miniconda.sh -b -p /opt/conda && \
    rm ~/miniconda.sh && \
    apt-get clean
ENV PATH /opt/conda/bin:$PATH

# Install torch with flash attention
RUN conda install -y ninja pytorch==2.2.2 torchvision torchaudio pytorch-cuda=11.8 cuda-nvcc cuda-python -c pytorch -c nvidia
RUN pip install --no-cache-dir --upgrade pip
RUN pip install --no-cache-dir flash-attn --no-build-isolation
RUN conda clean -ay

COPY pyproject.toml .
RUN mkdir olmo && touch olmo/__init__.py && \
    pip install --no-cache-dir .[train] && \
    pip uninstall -y ai2-olmo && \
    rm -rf olmo/

WORKDIR /app/olmo
