2025-05-21 17:48:45.353	devbox:0	train:417	INFO	CLI environment prepared
2025-05-21 17:48:45.454	devbox:0	train:433	INFO	Device is CPU. Updating config...
2025-05-21 17:48:45.455	devbox:0	train:97	INFO	Configuration:
2025-05-21 17:48:45.455	devbox:0	train:98	INFO	TrainConfig(run_name='OLMo-20M-deterministic-test', seed=6198, epoch=None, dry_run=False, model=ModelConfig(d_model=256, n_heads=8, n_kv_heads=None, clip_qkv=None, n_layers=8, mlp_ratio=8, mlp_hidden_size=None, activation_type='swiglu', block_type='sequential', block_group_size=1, alibi=False, alibi_bias_max=8.0, rope=True, rope_full_precision=True, rope_theta=10000, flash_attention=True, attention_dropout=0.0, multi_query_attention=None, attention_layer_norm=False, residual_dropout=0.0, embedding_dropout=0.0, embedding_layer_norm=False, layer_norm_type='rms', layer_norm_with_affine=True, layer_norm_eps=1e-06, attention_layer_norm_with_affine=False, max_sequence_length=4096, include_bias=False, bias_for_layer_norm=False, scale_logits=False, vocab_size=50280, embedding_size=50304, weight_tying=False, eos_token_id=0, pad_token_id=1, init_device='cpu', init_fn='normal', init_std=0.02, init_cutoff_factor=3.0, precision='amp_bf16', scale_emb_init=False, emb_init_std=None, norm_after=False), optimizer=OptimizerConfig(name='adamw', learning_rate=0.0006, weight_decay=0.1, betas=(0.9, 0.95), eps=1e-08, no_decay_norm_and_bias=None, selective_updates=False, decay_norm_and_bias=True, decay_embeddings=True, metrics_log_interval=10, record_update_metrics=False), scheduler=SchedulerConfig(name='cosine_with_warmup', units='steps', t_warmup=5000, t_max=None, alpha_f=0.1, grad_clip_warmup_steps=None, grad_clip_warmup_factor=None, warmup_min_lr=0.0), data=DataConfig(paths=['test_fixtures/dummy_data.npy'], memmap_dtype='uint16', datasets=None, label_mask_paths=None, pad_direction='right', generate_attention_mask=False, generate_doc_lengths=False, num_workers=1, drop_last=True, pin_memory=True, prefetch_factor=2, persistent_workers=False, timeout=0, seed=None, instance_filter=None, custom_dataset=None), restore_dataloader=True, fast_forward_batches=None, evaluators=[], eval_interval=100000, tokenizer=TokenizerConfig(identifier='tokenizers/allenai_gpt-neox-olmo-dolma-v1_5.json', truncate_direction='right'), save_folder='workspace/OLMo-20M-deterministic-test', remote_save_folder=None, canceled_check_interval=50, save_interval=1000, save_interval_unsharded=5000, save_interval_ephemeral=None, save_num_checkpoints_to_keep=-1, save_num_unsharded_checkpoints_to_keep=-1, save_overwrite=True, force_save_unsharded=False, no_pre_train_checkpoint=False, load_path=None, load_path_sharded_checkpointer=None, try_load_latest_save=False, reset_optimizer_state=False, reset_trainer_state=False, sharded_checkpointer='torch_legacy', new_style_checkpoints=None, max_duration='20ba', global_train_batch_size=1024, device_train_batch_size=1024, device_train_microbatch_size=16, device_eval_batch_size=16, eval_subset_num_batches=-1, eval_on_load=False, device_train_grad_accum=64, max_grad_norm=1.0, max_grad_norm_ratio=None, precision='amp_bf16', wandb=None, speed_monitor=SpeedMonitorConfig(window_size=20, gpu_flops_available=None), console_log_interval=1, gen1_gc_interval=1, compile=None, distributed_strategy='single', fsdp=FSDPConfig(use_orig_params=True, sharding_strategy=<ShardingStrategy.FULL_SHARD: 1>, wrapping_strategy=None, precision='pure', hybrid_sharding_num_model_replicas=None), ddp=DDPConfig(grad_sync_mode='batch', find_unused_params=False), single=SingleGPUConfig(device='auto'), softmax_auxiliary_loss=False, auxiliary_loss_multiplier=0.0001, time_limit=None, extra_steps_after_cancel=10, early_stopping_factor=None, save_data_indices=True, python_profiling=False, torch_profiling=False, stop_at=None, stop_after=None, activation_checkpointing=None, fused_loss=None, hf_datasets_cache_dir=None, module_outputs_save_steps=None)
2025-05-21 17:48:45.455	devbox:0	train:105	INFO	Saving config to workspace/OLMo-20M-deterministic-test/config.yaml
2025-05-21 17:48:46.037	devbox:0	olmo.data.iterable_dataset:79	INFO	Saving global data order indices...
2025-05-21 17:48:46.037	devbox:0	olmo.util:168	CRITICAL	Uncaught ValueError: cannot mmap an empty file
Traceback (most recent call last):
  File "/app/scripts/train.py", line 436, in <module>
    main(cfg)
  File "/app/scripts/train.py", line 132, in main
    train_loader = build_train_dataloader(cfg)
  File "/home/swebot/.local/lib/python3.10/site-packages/olmo/data/__init__.py", line 156, in build_train_dataloader
    dataset = IterableDataset(
  File "/home/swebot/.local/lib/python3.10/site-packages/olmo/data/iterable_dataset.py", line 73, in __init__
    self._build_and_save_global_indices()
  File "/home/swebot/.local/lib/python3.10/site-packages/olmo/data/iterable_dataset.py", line 82, in _build_and_save_global_indices
    global_indices_mmap = np.memmap(
  File "/home/swebot/.local/lib/python3.10/site-packages/numpy/core/memmap.py", line 268, in __new__
    mm = mmap.mmap(fid.fileno(), bytes, access=acc, offset=start)
ValueError: cannot mmap an empty file
